#!/usr/bin/env python3
"""
æµ‹è¯•å›½å†…æ”¿ç­– RSS æº
"""

import requests
import feedparser

POLICY_RSS_SOURCES = [
    ("æ–°åç¤¾", "http://www.news.cn/rss/world.xml"),
    ("ä¸­å›½æ”¿åºœç½‘-æ”¿ç­–", "https://rsshub.app/gov/zhengce"),
    ("ä¸­å›½æ”¿åºœç½‘-æœ€æ–°", "https://rsshub.app/gov/zhengce/zuixin"),
    ("å›½åŠ¡é™¢", "https://rsshub.app/gov/guowuyuan"),
    ("å‘æ”¹å§”", "https://rsshub.app/gov/ndrc"),
    ("è´¢æ”¿éƒ¨", "https://rsshub.app/gov/mof"),
    ("å•†åŠ¡éƒ¨", "https://rsshub.app/gov/mofcom"),
]

PROXY = {'http': 'http://127.0.0.1:1082', 'https': 'http://127.0.0.1:1082'}

def test_rss(name, url):
    try:
        print(f"\nğŸ“¡ æµ‹è¯•: {name}")
        print(f"   URL: {url}")
        
        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}
        response = requests.get(url, headers=headers, timeout=15, proxies=PROXY)
        
        if response.status_code != 200:
            print(f"   âŒ HTTP {response.status_code}")
            return False
        
        feed = feedparser.parse(response.content)
        
        if not feed.entries:
            print(f"   âš ï¸  æ— å†…å®¹")
            return False
        
        print(f"   âœ… æˆåŠŸ! {len(feed.entries)} æ¡")
        if feed.entries:
            first = feed.entries[0]
            print(f"   ğŸ“° ç¤ºä¾‹: {first.get('title', 'æ— æ ‡é¢˜')[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)[:60]}")
        return False

if __name__ == "__main__":
    print("="*60)
    print("ğŸ” æµ‹è¯•å›½å†…æ”¿ç­– RSS æº")
    print("="*60)
    
    working_sources = []
    
    for name, url in POLICY_RSS_SOURCES:
        if test_rss(name, url):
            working_sources.append((name, url))
    
    print("\n" + "="*60)
    print(f"âœ… å¯ç”¨æº: {len(working_sources)} ä¸ª")
    for name, url in working_sources:
        print(f"   â€¢ {name}: {url}")
