#!/usr/bin/env python3
"""
æ–°é—»å°é¢å›¾ç‰‡èŽ·å– - å¯é æ–¹æ¡ˆ
1. å°è¯•æŠ“å–æ–°é—»ç½‘é¡µçš„ og:image
2. å¤±è´¥æ—¶ä½¿ç”¨ Unsplash éšæœºå›¾ç‰‡ï¼ˆæŒ‰åˆ†ç±»ï¼‰
"""

import requests
import re
import urllib.parse
from pathlib import Path

# ä»£ç†é…ç½®
PROXY = {'http': 'http://127.0.0.1:1082', 'https': 'http://127.0.0.1:1082'}

# Unsplash åˆ†ç±»å›¾ç‰‡é›†ï¼ˆé«˜è´¨é‡ã€å…ç‰ˆæƒï¼‰
UNSPLASH_IMAGES = {
    'shanghai': [
        'https://images.unsplash.com/photo-1548919973-5cef591cdbc9?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1538428494232-9c0d8a3ab403?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1474181487882-5abf3f0ba6c2?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1505164294036-303dcdf97f8b?w=600&h=750&fit=crop',
    ],
    'world': [
        'https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1524661135-423995f22d0b?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1517976487492-5750f3195933?w=600&h=750&fit=crop',
    ],
    'ai': [
        'https://images.unsplash.com/photo-1677442136019-21780ecad995?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1620712943543-bcc4688e7485?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1531746790731-6c087fecd65a?w=600&h=750&fit=crop',
    ],
    'stocks': [
        'https://images.unsplash.com/photo-1611974765270-ca1258634369?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1590283603385-17ffb3a7f29f?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1611974789855-9c2a0a7236a3?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1468259943503-0c1955f43448?w=600&h=750&fit=crop',
    ],
    'policy': [
        'https://images.unsplash.com/photo-1577495508048-b635879837f1?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1555848962-6e79363ec58f?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1529107386315-e1a2ed48a620?w=600&h=750&fit=crop',
        'https://images.unsplash.com/photo-1578393091816-a949886a18c7?w=600&h=750&fit=crop',
    ]
}

import hashlib

def get_unsplash_image(category, title):
    """æ ¹æ®åˆ†ç±»èŽ·å– Unsplash å›¾ç‰‡ï¼ˆä½¿ç”¨æ ‡é¢˜hashç¡®ä¿ä¸€è‡´æ€§ï¼‰"""
    images = UNSPLASH_IMAGES.get(category, UNSPLASH_IMAGES['world'])
    # ä½¿ç”¨æ ‡é¢˜hashé€‰æ‹©å›¾ç‰‡ï¼Œç¡®ä¿ç›¸åŒæ ‡é¢˜æ€»æ˜¯å¾—åˆ°ç›¸åŒå›¾ç‰‡
    index = int(hashlib.md5(title.encode()).hexdigest(), 16) % len(images)
    return images[index]

def fetch_og_image(url):
    """ä»Žç½‘é¡µæŠ“å– og:imageï¼ˆå¸¦ç¼“å­˜å’Œè¶…æ—¶ï¼‰"""
    if not url or not url.startswith('http'):
        return None
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        # é™åˆ¶æ—¶é—´å’Œå¤§å°
        response = requests.get(
            url, 
            headers=headers, 
            timeout=5,  # 5ç§’è¶…æ—¶
            proxies=PROXY,
            stream=True
        )
        
        # åªè¯»å‰50KB
        content = b''
        for chunk in response.iter_content(chunk_size=1024):
            content += chunk
            if len(content) > 50000:
                break
        
        html = content.decode('utf-8', errors='ignore')
        
        # æŸ¥æ‰¾ og:image
        patterns = [
            r'<meta[^\u003e]*property="og:image"[^\u003e]*content="([^"]+)"',
            r'<meta[^\u003e]*content="([^"]+)"[^\u003e]*property="og:image"',
            r'<meta[^\u003e]*name="twitter:image"[^\u003e]*content="([^"]+)"',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, html, re.IGNORECASE)
            if match:
                image_url = match.group(1).strip()
                # å¤„ç†ç›¸å¯¹è·¯å¾„
                if image_url.startswith('//'):
                    image_url = 'https:' + image_url
                elif image_url.startswith('/'):
                    parsed = urllib.parse.urlparse(url)
                    image_url = f"{parsed.scheme}://{parsed.netloc}{image_url}"
                
                # éªŒè¯æ˜¯åˆæ³•URL
                if image_url.startswith('http'):
                    return image_url
        
        return None
    except Exception as e:
        return None

def get_news_image(title, url, category='general'):
    """
    èŽ·å–æ–°é—»å°é¢å›¾ç‰‡
    1. å°è¯•æŠ“å–åŽŸç½‘é¡µ og:image
    2. å¤±è´¥æ—¶ä½¿ç”¨ Unsplash åˆ†ç±»å›¾ç‰‡
    """
    # 1. å°è¯•æŠ“å–çœŸå®žå›¾ç‰‡ï¼ˆå¯¹æŸäº›åŸŸåæœ‰æ•ˆï¼‰
    if url and ('thepaper.cn' in url or 'sina.com.cn' in url or 'jiading' in url):
        real_image = fetch_og_image(url)
        if real_image:
            return {'url': real_image, 'type': 'real'}
    
    # 2. ä½¿ç”¨ Unsplash å›¾ç‰‡
    unsplash_url = get_unsplash_image(category, title)
    return {'url': unsplash_url, 'type': 'unsplash'}

if __name__ == '__main__':
    # æµ‹è¯•
    test_cases = [
        ('å˜‰å®šæ–°åŸŽå»ºè®¾æé€Ÿ', 'https://www.jiading.gov.cn/', 'shanghai'),
        ('SpaceX å‘å°„æˆåŠŸ', 'https://www.spacex.com', 'world'),
        ('OpenAI GPT-5 å‘å¸ƒ', 'https://openai.com', 'ai'),
    ]
    
    for title, url, cat in test_cases:
        result = get_news_image(title, url, cat)
        print(f"\nðŸ“ {title[:20]}...")
        print(f"   ðŸ“· {result['type']}: {result['url'][:60]}...")
