#!/usr/bin/env python3
"""
æµ‹è¯•æ›´å¤šä¸Šæµ·æ–°é—»æº
"""

import requests
import feedparser
import re

SHANGHAI_SOURCES = [
    # ä¸»è¦åª’ä½“
    ("æ¾æ¹ƒæ–°é—»", "https://feedx.net/rss/thepaper.xml"),
    ("è§£æ”¾æ—¥æŠ¥", "https://rsshub.app/wechat/mp/è§£æ”¾æ—¥æŠ¥"),
    ("æ–°æ°‘æ™šæŠ¥", "https://rsshub.app/wechat/mp/æ–°æ°‘æ™šæŠ¥"),
    
    # ä¸Šæµ·æœ¬åœ°
    ("ä¸Šæµ·å‘å¸ƒ", "https://rsshub.app/wechat/mp/ä¸Šæµ·å‘å¸ƒ"),
    ("æ–°é—»æ™¨æŠ¥", "https://rsshub.app/wechat/mp/æ–°é—»æ™¨æŠ¥"),
    ("ä¸œæ–¹ç½‘", "https://rsshub.app/eastday/sh"),
    
    # å˜‰å®šç›¸å…³
    ("ä¸Šæµ·å˜‰å®š", "https://rsshub.app/wechat/mp/ä¸Šæµ·å˜‰å®š"),
    ("å˜‰å®šå‘å¸ƒ", "https://www.jiading.gov.cn/rss"),
    
    # ç¤¾åŒº/æ°‘ç”Ÿ
    ("å‘¨åˆ°ä¸Šæµ·", "https://rsshub.app/wechat/mp/å‘¨åˆ°ä¸Šæµ·"),
    ("ä¸Šæµ·è§‚å¯Ÿ", "https://rsshub.app/wechat/mp/ä¸Šè§‚æ–°é—»"),
]

# å…³é”®è¯è¿‡æ»¤å™¨
JIADING_KEYWORDS = ['å˜‰å®š', 'å˜‰å®šåŒº', 'å—ç¿”', 'æ±Ÿæ¡¥', 'å®‰äº­', 'é©¬é™†', 'å¤–å†ˆ', 'å¾è¡Œ', 'åäº­', 'èŠå›­', 'æ–°æˆè·¯', 'çœŸæ–°', 'å˜‰å®šæ–°åŸ', 'å˜‰å®šå·¥ä¸šåŒº']
SEASON_KEYWORDS = ['ç«‹æ˜¥', 'é›¨æ°´', 'æƒŠè›°', 'æ˜¥åˆ†', 'æ¸…æ˜', 'è°·é›¨', 'ç«‹å¤', 'å°æ»¡', 'èŠ’ç§', 'å¤è‡³', 'å°æš‘', 'å¤§æš‘',
                   'ç«‹ç§‹', 'å¤„æš‘', 'ç™½éœ²', 'ç§‹åˆ†', 'å¯’éœ²', 'éœœé™', 'ç«‹å†¬', 'å°é›ª', 'å¤§é›ª', 'å†¬è‡³', 'å°å¯’', 'å¤§å¯’',
                   'æ˜¥èŠ‚', 'å…ƒå®µ', 'æ¸…æ˜', 'ç«¯åˆ', 'ä¸­ç§‹', 'é‡é˜³', 'å†¬è‡³', 'è…Šå…«', 'å°å¹´', 'é™¤å¤•']
COMMUNITY_KEYWORDS = ['ç¤¾åŒº', 'è¡—é“', 'å±…å§”ä¼š', 'ä¸šå§”ä¼š', 'ç‰©ä¸š', 'é‚»é‡Œ', 'ä¾¿æ°‘æœåŠ¡', 'ä¸ºè€æœåŠ¡', 'å…»è€', 'æ‰˜è‚²', 'èœåœº', 'æ—§æ”¹', 'åŠ è£…ç”µæ¢¯']

def is_relevant(title, summary=""):
    """åˆ¤æ–­æ˜¯å¦ä¸å˜‰å®š/èŠ‚æ°”/ç¤¾åŒºç›¸å…³"""
    text = (title + summary).lower()
    
    # æ£€æŸ¥å„ç±»å…³é”®è¯
    has_jiading = any(kw in text for kw in JIADING_KEYWORDS)
    has_season = any(kw in text for kw in SEASON_KEYWORDS)
    has_community = any(kw in text for kw in COMMUNITY_KEYWORDS)
    
    return {
        'jiading': has_jiading,
        'season': has_season,
        'community': has_community,
        'score': int(has_jiading) * 3 + int(has_season) * 2 + int(has_community) * 1
    }

def test_source(name, url):
    """æµ‹è¯• RSS æº"""
    try:
        print(f"\nğŸ“¡ æµ‹è¯•: {name}")
        print(f"   URL: {url[:60]}...")
        
        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}
        
        # ä½¿ç”¨ä»£ç†
        proxies = {'http': 'http://127.0.0.1:1082', 'https': 'http://127.0.0.1:1082'}
        response = requests.get(url, headers=headers, timeout=15, proxies=proxies)
        
        if response.status_code != 200:
            print(f"   âŒ HTTP {response.status_code}")
            return None
        
        feed = feedparser.parse(response.content)
        
        if not feed.entries:
            print(f"   âš ï¸ æ— å†…å®¹")
            return None
        
        # åˆ†æå†…å®¹ç›¸å…³æ€§
        relevant_count = 0
        sample_items = []
        
        for entry in feed.entries[:10]:
            title = entry.get("title", "")
            result = is_relevant(title)
            
            if result['score'] > 0:
                relevant_count += 1
                tags = []
                if result['jiading']: tags.append('ğŸ å˜‰å®š')
                if result['season']: tags.append('ğŸŒ¸èŠ‚æ°”')
                if result['community']: tags.append('ğŸ‘¥ç¤¾åŒº')
                
                sample_items.append({
                    'title': title[:50],
                    'tags': tags,
                    'score': result['score']
                })
        
        print(f"   âœ… æˆåŠŸ! {len(feed.entries)} æ¡å†…å®¹")
        print(f"   ğŸ¯ ç›¸å…³æ–°é—»: {relevant_count} æ¡")
        
        if sample_items[:3]:
            print(f"   ğŸ“° ç¤ºä¾‹:")
            for item in sorted(sample_items, key=lambda x: x['score'], reverse=True)[:3]:
                print(f"      â€¢ {item['title']}... {' '.join(item['tags'])}")
        
        return {
            'name': name,
            'url': url,
            'total': len(feed.entries),
            'relevant': relevant_count
        }
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {str(e)[:60]}")
        return None

if __name__ == "__main__":
    print("="*70)
    print("ğŸ” æµ‹è¯•ä¸Šæµ·æ–°é—»æº (å¸¦å˜‰å®š/èŠ‚æ°”/ç¤¾åŒºå…³é”®è¯è¿‡æ»¤)")
    print("="*70)
    
    working_sources = []
    
    for name, url in SHANGHAI_SOURCES:
        result = test_source(name, url)
        if result:
            working_sources.append(result)
    
    print("\n" + "="*70)
    print(f"âœ… å¯ç”¨æº: {len(working_sources)} ä¸ª")
    print("\næŒ‰ç›¸å…³æ–°é—»æ•°é‡æ’åº:")
    for src in sorted(working_sources, key=lambda x: x['relevant'], reverse=True):
        print(f"   â€¢ {src['name']}: {src['relevant']} æ¡ç›¸å…³ / {src['total']} æ¡æ€»è®¡")
    
    print("\nğŸ’¡ æ¨èé…ç½®:")
    for src in working_sources[:5]:
        print(f"   {src['name']}: {src['url']}")
